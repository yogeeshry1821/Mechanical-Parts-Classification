{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"trusted":true},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'PIL'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mPIL\u001b[39;00m \u001b[39mimport\u001b[39;00m Image\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mskimage\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m \u001b[39mimport\u001b[39;00m imread\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mskimage\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransform\u001b[39;00m \u001b[39mimport\u001b[39;00m rescale, resize\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'PIL'"]}],"source":["from PIL import Image\n","from skimage.io import imread\n","from skimage.transform import rescale, resize\n","import os\n","import glob\n","import string\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from keras import applications\n","import keras\n","from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D\n","from keras.models import Sequential\n","from keras.utils import to_categorical\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sn\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["path  = \"/data/blnw-images-224\"\n","os.chdir(path)\n","category_list=os.listdir(path)\n","category_list"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["list_of_image = glob.glob(\"**/*.png\")\n","list_of_folders = glob.glob(\"**\")\n","print(\"Total number of files \" + str(len(list_of_image)) )#Total data\n","print(\"Total Number of classes \"+ str(len(list_of_folders))) #Total Number of classes|"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#INDEX for Class number and Serial Number\n","Class_Dict = {}\n","for i in range(len(list_of_folders)):\n","    Class_Dict[i] = list_of_folders[i] \n","\n","Class_Dict"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Converts the class type into integers according to their order in the folder\n","# and appends to the list Y_list\n","Y_list = []\n","for i, data in enumerate(list_of_folders,0):\n","    list_of_images_in_folder = glob.glob(data+\"/*.png\") #check for .JPEG or .jpg or .png\n","    for j in list_of_images_in_folder:\n","        Y_list.append(i)\n","\n","Y = np.asarray(Y_list)\n","Y = Y.reshape(-1,1)\n","Y.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# to Count the number of files in each category(i.e. folder). \n","# Compare with number of files in the folder.\n","np.unique(Y)\n","unique, counts = np.unique(Y, return_counts=True)\n","dict(zip(unique, counts)) "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["image_list = []\n","for i,each in enumerate(list_of_image,1):\n","    im = imread(each, as_gray = True) #Convert images to gray and read as an array \n","    image_list.append(im) #add to this list"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["X = np.asarray(image_list) #Convert the list into array\n","X.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["X_ref = X #To keep the dimensions\n","X = X.reshape(-1, X_ref.shape[1],X_ref.shape[2], 1) #Convert to format usable by our model\n","X.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Visualise an image \n","plt.imshow(X[0].reshape(X_ref.shape[1],X_ref.shape[2]), cmap = plt.cm.binary)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Visualisation for classes\n","plt.figure(figsize=(20,20));\n","n = 2 #Class number {0: 'nut', 1: 'locatingpin', 2: 'bolt', 3: 'washer'}\n","num = 100 #num of data to visualize from the cluster\n","for i in range(1,num): \n","    plt.subplot(10, 10, i); #(Number of rows, Number of column per row, item number)\n","    plt.imshow(X[i+(1904*n)].reshape(X.shape[1], X.shape[2]), cmap = plt.cm.binary);\n","    \n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Training split\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=0.8,test_size=0.2, random_state=1) "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(\"Shape of training data \" + str(X_train.shape) )\n","print(\"Shape of testing data \"+ str(X_test.shape) )\n","print(\"Shape of training label \"+ str(y_train.shape) )\n","print(\"Shape of testing label \"+ str(y_test.shape) )"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["Y_train_one_hot = to_categorical(y_train)\n","Y_train_one_hot.shape #One hot encoding of Y"]},{"cell_type":"markdown","metadata":{},"source":["# Sequential"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Creation of a CNN . Sequential Model\n","model = Sequential()\n","model.add(Conv2D(64, (3,3), input_shape=(224, 224, 1))) #input_shape matches our input image\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Conv2D(64, (3,3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Flatten())\n","model.add(Dense(64))\n","model.add(Dense(4)) #data of four types\n","model.add(Activation('softmax'))\n","model.compile(loss=keras.losses.categorical_crossentropy, \n","      optimizer=keras.optimizers.Adam(),metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"trusted":true},"outputs":[],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["Y_test_one_hot = to_categorical(y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"trusted":true},"outputs":[],"source":["no_epochs = 15\n","history = model.fit(X_train, Y_train_one_hot, batch_size=64, \n","                    epochs = no_epochs, \n","                    validation_data=(X_test, Y_test_one_hot)) #Actual Training of model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["loss_train = history.history['loss']\n","loss_val = history.history['val_loss']\n","epochs = range(1,no_epochs+1)\n","plt.plot(epochs, loss_train, 'g', label='Training loss')\n","plt.plot(epochs, loss_val, 'b', label='validation loss')\n","plt.title('Training and Validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["loss_train = history.history['accuracy']\n","loss_val = history.history['val_accuracy']\n","epochs = range(1,no_epochs+1)\n","plt.plot(epochs, loss_train, 'g', label='Training Accuracy')\n","plt.plot(epochs, loss_val, 'b', label='validation Accuracy')\n","plt.title('Training and Validation accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","\n","predictions = model.predict(X_test,batch_size=64, verbose=0)\n","y_classes = predictions.argmax(axis=-1)\n","cm = confusion_matrix(y_test, y_classes)\n","print(cm)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#to print confusion matrix\n","def print_cm(cm, labels, hide_zeroes=False, hide_diagonal=False, hide_threshold=None):\n","    \"\"\"pretty print for confusion matrixes\"\"\"\n","    columnwidth = max([len(x) for x in labels] + [5])  # 5 is value length\n","    empty_cell = \" \" * columnwidth\n","    # Print header\n","    print(\"    \" + empty_cell, end=\" \")\n","    for label in labels:\n","        print(\"%{0}s\".format(columnwidth) % label, end=\" \")\n","    print()\n","    # Print rows\n","    for i, label1 in enumerate(labels):\n","        print(\"    %{0}s\".format(columnwidth) % label1, end=\" \")\n","        for j in range(len(labels)):\n","            cell = \"%{0}.1f\".format(columnwidth) % cm[i, j]\n","            if hide_zeroes:\n","                cell = cell if float(cm[i, j]) != 0 else empty_cell\n","            if hide_diagonal:\n","                cell = cell if i != j else empty_cell\n","            if hide_threshold:\n","                cell = cell if cm[i, j] > hide_threshold else empty_cell\n","            print(cell, end=\" \")\n","        print()\n","\n","# first generate with specified labels\n","cm = confusion_matrix(y_test, y_classes)\n","# then print it in a pretty way\n","print_cm(cm, category_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["array = cm\n","df_cm = pd.DataFrame(array, index = [i for i in category_list],\n","                  columns = [i for i in category_list])\n","plt.figure(figsize = (10,7))\n","sn.heatmap(df_cm, annot=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"},"vscode":{"interpreter":{"hash":"a42ccb73e7d9bfdf27e036f1d2b8b681e55fc0743cc5586bc2474d4a60f4b886"}}},"nbformat":4,"nbformat_minor":4}
